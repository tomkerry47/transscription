#!/usr/bin/env python3
"""
Real-time Whisper WebSocket Server for THRIVE Assessment Tool
VERSION 3 - Enhanced with real-time self-correction and phrase management
Based on techniques from davabase/whisper_real_time
"""

import asyncio
import json
import logging
import numpy as np
import torch
import whisper
import websockets
from websockets.exceptions import ConnectionClosed
import threading
import time
from collections import deque
from datetime import datetime, timedelta

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WhisperTranscriber:
    def __init__(self, model_name="medium", device=None):
        """Initialize Whisper model with real-time phrase management"""
        if device is None:
            device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # Validate model name
        if not self._validate_model(model_name):
            logger.warning(f"Model '{model_name}' may not be available. Falling back to 'medium'.")
            model_name = "medium"
        
        logger.info(f"Loading Whisper model '{model_name}' on device: {device}")
        self.model = whisper.load_model(model_name, device=device)
        self.device = device
        
        # Audio parameters
        self.sample_rate = 16000
        self.min_chunk_duration = 1.0  # Minimum audio for transcription
        self.phrase_timeout = 3.0  # Seconds of silence before phrase is complete
        self.min_chunk_samples = int(self.sample_rate * self.min_chunk_duration)
        
        # Real-time phrase management (inspired by GitHub repo)
        self.phrase_bytes = bytes()
        self.phrase_time = None
        self.current_phrase_id = 0
        self.last_transcription = ""
        
        # Accumulated final transcripts
        self.accumulated_final_text = ""
        self.current_partial_text = ""
        
        # Audio buffer
        self.audio_buffer = deque()
        self.buffer_lock = threading.Lock()
        
        logger.info(f"Real-time transcriber initialized with {self.phrase_timeout}s phrase timeout")
    
    def _validate_model(self, model_name):
        """Validate if the model name is supported"""
        valid_models = [
            "tiny", "base", "small", "medium", "large", 
            "large-v1", "large-v2", "large-v3", "large-v3-turbo"
        ]
        return model_name in valid_models
    
    def add_audio_data(self, audio_bytes):
        """Add raw audio data to buffer"""
        try:
            with self.buffer_lock:
                self.audio_buffer.extend(audio_bytes)
        except Exception as e:
            logger.error(f"Error adding audio data: {e}")
    def get_transcription_update(self):
        """Get real-time transcription update with proper text accumulation"""
        try:
            now = datetime.utcnow()
            
            with self.buffer_lock:
                if len(self.audio_buffer) < self.min_chunk_samples:
                    return None
                
                # Check if phrase is complete (silence timeout)
                phrase_complete = False
                if self.phrase_time and now - self.phrase_time > timedelta(seconds=self.phrase_timeout):
                    # Phrase is complete - finalize current partial text
                    if self.current_partial_text.strip():
                        # Add current partial to accumulated final text
                        if self.accumulated_final_text:
                            self.accumulated_final_text += " " + self.current_partial_text.strip()
                        else:
                            self.accumulated_final_text = self.current_partial_text.strip()
                        
                        # Send final result for the completed phrase
                        final_result = {
                            "text": self.current_partial_text.strip(),
                            "is_final": True,
                            "phrase_id": self.current_phrase_id,
                            "accumulated_text": self.accumulated_final_text,
                            "confidence": 1.0,
                            "timestamp": now.isoformat()
                        }
                        
                        # Reset for new phrase
                        self.current_partial_text = ""
                        self.phrase_bytes = bytes()
                        self.current_phrase_id += 1
                        self.last_transcription = ""
                        
                        logger.info(f"Final phrase {self.current_phrase_id-1}: {final_result['text']}")
                        return final_result
                
                # Update phrase time
                self.phrase_time = now
                
                # Get available audio data
                available_samples = len(self.audio_buffer)
                chunk_size = min(available_samples, self.sample_rate * 4)  # Max 4 seconds
                audio_data = bytes([self.audio_buffer.popleft() for _ in range(chunk_size)])
                
                # Add to current phrase
                self.phrase_bytes += audio_data
                
                # Convert to numpy array for Whisper
                audio_np = np.frombuffer(self.phrase_bytes, dtype=np.int16).astype(np.float32) / 32768.0
                
                # Transcribe the accumulated phrase
                result = self.model.transcribe(
                    audio_np,
                    fp16=torch.cuda.is_available(),
                    language="en",
                    word_timestamps=False,
                    condition_on_previous_text=True
                )
                
                text = result.get("text", "").strip()
                
                if text and text != self.last_transcription:
                    # Update current partial text
                    self.current_partial_text = text
                    self.last_transcription = text
                    
                    # Send partial result
                    partial_result = {
                        "text": text,
                        "is_final": False,
                        "phrase_id": self.current_phrase_id,
                        "accumulated_text": self.accumulated_final_text,
                        "confidence": 1.0,
                        "timestamp": now.isoformat()
                    }
                    
                    logger.info(f"Partial phrase {self.current_phrase_id}: {text}")
                    return partial_result
                
        except Exception as e:
            logger.error(f"Transcription error: {e}")
        
        return None

class WebSocketServer:
    def __init__(self, host="0.0.0.0", port=8000, model_name="medium"):
        self.host = host
        self.port = port
        self.transcriber = WhisperTranscriber(model_name=model_name)
        self.active_connections = set()
        logger.info(f"Real-time WebSocket server initialized with {model_name} model")
    
    async def handle_client(self, websocket):
        """Handle WebSocket client connection"""
        path = websocket.path if hasattr(websocket, 'path') else "/ws/transcribe"
        
        if path != "/ws/transcribe":
            logger.warning(f"Client attempted connection to invalid path: {path}")
            await websocket.close(code=1008, reason="Invalid path")
            return
            
        client_id = f"{websocket.remote_address[0]}:{websocket.remote_address[1]}"
        logger.info(f"Client connected: {client_id}")
        self.active_connections.add(websocket)
        
        # Start real-time transcription task
        transcription_task = asyncio.create_task(
            self.real_time_transcription_loop(websocket, client_id)
        )
        
        try:
            async for message in websocket:
                if isinstance(message, bytes):
                    # Raw audio data
                    logger.debug(f"Received {len(message)} bytes from {client_id}")
                    self.transcriber.add_audio_data(message)
                else:
                    # Control messages
                    try:
                        data = json.loads(message)
                        if data.get("type") == "start":
                            logger.info(f"Starting real-time transcription for {client_id}")
                        elif data.get("type") == "stop":
                            logger.info(f"Stopping transcription for {client_id}")
                            break
                    except json.JSONDecodeError:
                        logger.warning(f"Invalid JSON from {client_id}: {message}")
                        
        except ConnectionClosed:
            logger.info(f"Client disconnected: {client_id}")
        except Exception as e:
            logger.error(f"Error handling client {client_id}: {e}")
        finally:
            self.active_connections.discard(websocket)
            transcription_task.cancel()
            logger.info(f"Cleaned up connection for {client_id}")
    
    async def real_time_transcription_loop(self, websocket, client_id):
        """Real-time transcription loop with self-correction"""
        try:
            last_phrase_id = -1
            
            while websocket in self.active_connections:
                # Get transcription update
                result = self.transcriber.get_transcription_update()
                
                if result:
                    # Send update to client
                    message = json.dumps(result)
                    await websocket.send(message)
                    
                    # Log the type of update
                    update_type = "FINAL" if result["is_final"] else "PARTIAL"
                    if result["phrase_id"] != last_phrase_id:
                        logger.info(f"New phrase {result['phrase_id']} started for {client_id}")
                        last_phrase_id = result["phrase_id"]
                    
                    logger.debug(f"Sent {update_type} to {client_id}: {result['text'][:50]}...")
                
                # Small delay for CPU efficiency
                await asyncio.sleep(0.1)
                
        except asyncio.CancelledError:
            logger.info(f"Real-time transcription cancelled for {client_id}")
        except Exception as e:
            logger.error(f"Real-time transcription error for {client_id}: {e}")
    
    async def start_server(self):
        """Start the WebSocket server"""
        logger.info(f"Starting real-time Whisper WebSocket server v3 on {self.host}:{self.port}")
        
        server = await websockets.serve(
            self.handle_client,
            self.host,
            self.port
        )
        
        logger.info(f"✅ Real-time Whisper server v3 listening at ws://{self.host}:{self.port}/ws/transcribe")
        logger.info("✅ Server ready for real-time transcription with self-correction")
        logger.info(f"✅ Using model on device: {self.transcriber.device}")
        logger.info(f"✅ Phrase timeout: {self.transcriber.phrase_timeout}s")
        
        return server

def main():
    """Main function to start the server"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Real-time Whisper WebSocket Server v3 for THRIVE")
    parser.add_argument("--host", default="0.0.0.0", help="Host to bind to")
    parser.add_argument("--port", type=int, default=8000, help="Port to bind to")
    parser.add_argument("--model", default="medium", 
                       choices=["tiny", "base", "small", "medium", "large", "large-v1", "large-v2", "large-v3", "large-v3-turbo"],
                       help="Whisper model to use")
    parser.add_argument("--phrase_timeout", default=3.0, type=float,
                       help="Seconds of silence before phrase is considered complete")
    
    args = parser.parse_args()
    
    # Check CUDA availability
    if torch.cuda.is_available():
        logger.info(f"✅ CUDA available: {torch.cuda.get_device_name()}")
        logger.info(f"✅ CUDA version: {torch.version.cuda}")
    else:
        logger.warning("⚠️  CUDA not available, using CPU (will be slower)")
    
    # Show configuration
    logger.info(f"🎯 Model: {args.model}")
    logger.info(f"⏱️ Phrase timeout: {args.phrase_timeout}s")
    
    if args.model == "large-v3-turbo":
        logger.info("🚀 Using large-v3-turbo for highest quality and speed!")
    elif args.model == "large-v3":
        logger.info("🎯 Using large-v3 for highest quality!")
    elif args.model == "medium":
        logger.info("⚖️ Using medium model for balanced performance!")
    
    # Create server with custom phrase timeout
    server = WebSocketServer(host=args.host, port=args.port, model_name=args.model)
    server.transcriber.phrase_timeout = args.phrase_timeout
    
    async def run_server():
        """Run the server with proper error handling"""
        try:
            server_instance = await server.start_server()
            logger.info("🚀 Real-time server v3 started successfully! Press Ctrl+C to stop.")
            logger.info("🔄 Server will provide real-time updates with self-correction")
            
            # Keep the server running indefinitely
            await server_instance.wait_closed()
            
        except Exception as e:
            logger.error(f"❌ Server error: {e}")
            raise
    
    try:
        asyncio.run(run_server())
    except KeyboardInterrupt:
        logger.info("🛑 Server shutdown requested by user")
    except Exception as e:
        logger.error(f"❌ Fatal server error: {e}")

if __name__ == "__main__":
    main()
